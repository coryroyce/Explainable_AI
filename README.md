# Explainable AI

Opening the "black box" of machine learning models has been huge in not only understanding the models we create, but then also communicating the insights to others. As I encounter different use cases for explainable AI, I'm distilling the insights into manageable chunks and sharing them openly.

## Explainability with Multi Target Regression Models

- Demonstrate a way to explore the explainability of multi target regrssion models with [SHAP](https://github.com/slundberg/shap).
- View ipynb [here](https://github.com/coryroyce/Explainable_AI/blob/main/Notebooks/SHAP_Values_for_Multiple_Regression_Models.ipynb) (Recommend downloading and running the entire notebook in [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb))

<br/>

<img align="left" width="250" height="150" src="https://github.com/coryroyce/Explainable_AI/blob/main/Reference_Material/Images/SHAP_Summary_Plot_01.png"> **[SHAP Values for Multi Target Regression Models](https://github.com/coryroyce/Explainable_AI/blob/main/Notebooks/SHAP_Values_for_Multiple_Regression_Models.ipynb)**

Apply Shapely values to a multi target regression model to explore how the features effects each of the target/labels independently.

<br/>
